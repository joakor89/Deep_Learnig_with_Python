{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba64b27",
   "metadata": {},
   "source": [
    "# DeepDream\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf82c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System\n",
    "import os, shutil, pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Math Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# TensorFlow Datasets\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4c8e5",
   "metadata": {},
   "source": [
    "### Implementing DeepDream in Keras\n",
    "\n",
    "#### Fetching the Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c840839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_image_path = keras.utils.get_file(\n",
    "#     \"coast.jpg\", origin=\"https://img-datasets.s3.amazonaws.com/coast.jpg\")\n",
    "\n",
    "# plt.axis(\"off\")\n",
    "# plt.imshow(keras.utils.load_img(base_image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72074d4",
   "metadata": {},
   "source": [
    "#### Instantiating a Pretrained InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7b0e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = inception_v3.InceptionV3(weights=\"imagenet\", include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40be9c",
   "metadata": {},
   "source": [
    "#### Configuring The Contribution of Each Layer to The DeepDream Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cfc9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_settings = {\n",
    "#     \"mixed4\": 1.0,\n",
    "#     \"mixed5\": 1.5,\n",
    "#     \"mixed6\": 2.0,\n",
    "#     \"mixed7\": 2.5,\n",
    "# }\n",
    "# outputs_dict = dict(\n",
    "#     [\n",
    "#         (layer.name, layer.output)\n",
    "#         for layer in [model.get_layer(name) for name in layer_settings.keys()]\n",
    "#     ]\n",
    "# )\n",
    "# feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cd109",
   "metadata": {},
   "source": [
    "#### The DeepDream Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5322da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_loss(input_image):\n",
    "#     features = feature_extractor(input_image)\n",
    "#     loss = tf.zeros(shape=())\n",
    "#     for name in features.keys():\n",
    "#         coeff = layer_settings[name]\n",
    "#         activation = features[name]\n",
    "#         loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :]))\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5132bbef",
   "metadata": {},
   "source": [
    "#### The DeepDream Gradient Ascent Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f41316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def gradient_ascent_step(image, learning_rate):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(image)\n",
    "#         loss = compute_loss(image)\n",
    "#     grads = tape.gradient(loss, image)\n",
    "#     grads = tf.math.l2_normalize(grads)\n",
    "#     image += learning_rate * grads\n",
    "#     return loss, image\n",
    "\n",
    "\n",
    "# def gradient_ascent_loop(image, iterations, learning_rate, max_loss=None):\n",
    "#     for i in range(iterations):\n",
    "#         loss, image = gradient_ascent_step(image, learning_rate)\n",
    "#         if max_loss is not None and loss > max_loss:\n",
    "#             break\n",
    "#         print(f\"... Loss value at step {i}: {loss:.2f}\")\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fa1606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step = 20.\n",
    "# num_octave = 3\n",
    "# octave_scale = 1.4\n",
    "# iterations = 30\n",
    "# max_loss = 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e615245",
   "metadata": {},
   "source": [
    "#### Image Processing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d780dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image_path):\n",
    "#     img = keras.utils.load_img(image_path)\n",
    "#     img = keras.utils.img_to_array(img)\n",
    "#     img = np.expand_dims(img, axis=0)\n",
    "#     img = keras.applications.inception_v3.preprocess_input(img)\n",
    "#     return img\n",
    "\n",
    "# def deprocess_image(img):\n",
    "#     img = img.reshape((img.shape[1], img.shape[2], 3))\n",
    "#     img /= 2.0\n",
    "#     img += 0.5\n",
    "#     img *= 255.\n",
    "#     img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35299fd3",
   "metadata": {},
   "source": [
    "#### Running Gradient Ascent over Multiple Successive \"octaves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aac281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_img = preprocess_image(base_image_path)\n",
    "# original_shape = original_img.shape[1:3]\n",
    "\n",
    "# successive_shapes = [original_shape]\n",
    "\n",
    "# for i in range(1, num_octave):\n",
    "#     shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "#     successive_shapes.append(shape)\n",
    "# successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])\n",
    "\n",
    "# img = tf.identity(original_img)\n",
    "\n",
    "# for i, shape in enumerate(successive_shapes):\n",
    "#     print(f\"Processing octave {i} with shape {shape}\")\n",
    "#     img = tf.image.resize(img, shape)\n",
    "#     img = gradient_ascent_loop(\n",
    "#         img, iterations=iterations, learning_rate=step, max_loss=max_loss\n",
    "#     )\n",
    "#     upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)\n",
    "#     same_size_original = tf.image.resize(original_img, shape)\n",
    "#     lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "#     img += lost_detail\n",
    "#     shrunk_original_img = tf.image.resize(original_img, shape)\n",
    "\n",
    "# keras.utils.save_img(\"dream.png\", deprocess_image(img.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160327ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
