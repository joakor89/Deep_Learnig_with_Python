{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a83327b",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning for Computer Vision\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3aee5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# TensorFlow Datasets\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "# Math Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "import os, shutil, pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6c1e6",
   "metadata": {},
   "source": [
    "### Introduction to ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc27380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a small convnet\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d3f037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104202 (407.04 KB)\n",
      "Trainable params: 104202 (407.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Displaying the model's summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96cb4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1501 - accuracy: 0.9538\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0445 - accuracy: 0.9866\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0294 - accuracy: 0.9909\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0228 - accuracy: 0.9926\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0180 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x321802590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a convnet on MNIST images\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Train set\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "# Test set\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ea8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9923\n",
      "Test accuracy:  0.992300\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the convnet\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc: 3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12494e",
   "metadata": {},
   "source": [
    "#### The MaxPooling Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8968019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An incorrectly structure convnet missing its max-pooling layers\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417f8beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 128)       73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 61952)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                619530    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 712202 (2.72 MB)\n",
      "Trainable params: 712202 (2.72 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_max_pool.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd4d46",
   "metadata": {},
   "source": [
    "### Training ConvNet from Scratch\n",
    "\n",
    "### Note:\n",
    "\n",
    "Remaining code was performed in Google Colab. I strongly suggest you to do the same.\n",
    "\n",
    "The following code is a batch of snippet performed there based on computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c97d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e009ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "084ad41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003f9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "312444ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -qq dogs-vs-cats.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0cfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -qq train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99bfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying images to training, validation, and test directories\n",
    "import os, shutil, pathlib\n",
    "\n",
    "# original_dir = pathlib.Path(\"train\")\n",
    "# new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "# def make_subset(subset_name, start_index, end_index):\n",
    "#     for category in (\"cat\", \"dog\"):\n",
    "#         dir = new_base_dir / subset_name / category\n",
    "#         os.makedirs(dir)\n",
    "#         fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "#         for fname in fnames:\n",
    "#             shutil.copyfile(src=original_dir / fname,\n",
    "#                             dst=dir / fname)\n",
    "\n",
    "# make_subset(\"train\", start_index=0, end_index=1000)\n",
    "# make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "# make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a61062",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b32672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbeaad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 178, 178, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 89, 89, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 87, 87, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 43, 43, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 41, 41, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 20, 20, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 9, 9, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 12545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 991041 (3.78 MB)\n",
      "Trainable params: 991041 (3.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953916c",
   "metadata": {},
   "source": [
    "##### Configuring the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f99c51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36de7f",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eab01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using image_dataset_from_directory to read images\n",
    "\n",
    "# from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "# train_dataset = image_dataset_from_directory(\n",
    "#     new_base_dir / \"train\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)\n",
    "# validation_dataset = image_dataset_from_directory(\n",
    "#     new_base_dir / \"validation\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)\n",
    "# test_dataset = image_dataset_from_directory(\n",
    "#     new_base_dir / \"test\",\n",
    "#     image_size=(180, 180),\n",
    "#     batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ebe47",
   "metadata": {},
   "source": [
    "##### Understanding TensorFlow 'Datasets' objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ac1c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "random_numbers = np.random.normal(size=(1000, 16))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f6ab225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13dcce65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 16)\n",
      "(32, 16)\n",
      "(32, 16)\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = dataset.batch(32)\n",
    "for i, element in enumerate(batched_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edfed565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n",
    "for i, element in enumerate(reshaped_dataset):\n",
    "    print(element.shape)\n",
    "    if i >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ec074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the shapes of the data and labels yielded by the 'Dataset'\n",
    "\n",
    "for data_batch, labels_batch in train_dataset:\n",
    "    print(\"data batch shape:\", data_batch.shape)\n",
    "    print(\"labels batch shape:\", labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f10ecd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model using a Dataset\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6301296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying curves of loss and accuracy during training\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a33c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test set\n",
    "\n",
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84abc0",
   "metadata": {},
   "source": [
    "#### Using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "294eda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data augmentation stage to add to an image model\n",
    "\n",
    "# data_augmentation = keras.Sequential(\n",
    "#     [\n",
    "#         layers.RandomFlip(\"horizontal\"),\n",
    "#         layers.RandomRotation(0.1),\n",
    "#         layers.RandomZoom(0.2),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3814c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some randomly augmented training images\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, _ in train_dataset.take(1):\n",
    "#     for i in range(9):\n",
    "#         augmented_images = data_augmentation(images)\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96c41369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a new convnet that includes image augmentation and dropout\n",
    "\n",
    "# inputs = keras.Input(shape=(180, 180, 3))\n",
    "# x = data_augmentation(inputs)\n",
    "# x = layers.Rescaling(1./255)(x)\n",
    "# x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#               optimizer=\"rmsprop\",\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e351fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the regularized convnet\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         filepath=\"convnet_from_scratch_with_augmentation.keras\",\n",
    "#         save_best_only=True,\n",
    "#         monitor=\"val_loss\")\n",
    "# ]\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=100,\n",
    "#     validation_data=validation_dataset,\n",
    "#     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aac28691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test set\n",
    "\n",
    "# test_model = keras.models.load_model(\n",
    "#     \"convnet_from_scratch_with_augmentation.keras\")\n",
    "# test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "# print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f198d6",
   "metadata": {},
   "source": [
    "### Leveraging a Pretrained Model\n",
    "\n",
    "#### Feature Extraction with a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "043443fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the VGG16 convolutional base\n",
    "\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0796a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b73522",
   "metadata": {},
   "source": [
    "#### Fast feature extraction without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16b936a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the VGG16 features and corresponding labels\n",
    "\n",
    "# def get_features_and_labels(dataset):\n",
    "#     all_features = []\n",
    "#     all_labels = []\n",
    "#     for images, labels in dataset:\n",
    "#         preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "#         features = conv_base.predict(preprocessed_images)\n",
    "#         all_features.append(features)\n",
    "#         all_labels.append(labels)\n",
    "#     return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "# train_features, train_labels =  get_features_and_labels(train_dataset)\n",
    "# val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
    "# test_features, test_labels =  get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38f02191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a38a584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and training the densely connected classifier\n",
    "\n",
    "# inputs = keras.Input(shape=(5, 5, 512))\n",
    "# x = layers.Flatten()(inputs)\n",
    "# x = layers.Dense(256)(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs, outputs)\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#               optimizer=\"rmsprop\",\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#       filepath=\"feature_extraction.keras\",\n",
    "#       save_best_only=True,\n",
    "#       monitor=\"val_loss\")\n",
    "# ]\n",
    "# history = model.fit(\n",
    "#     train_features, train_labels,\n",
    "#     epochs=20,\n",
    "#     validation_data=(val_features, val_labels),\n",
    "#     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41f9d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "\n",
    "# acc = history.history[\"accuracy\"]\n",
    "# val_acc = history.history[\"val_accuracy\"]\n",
    "# loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "# plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "# plt.title(\"Training and validation accuracy\")\n",
    "# plt.legend()\n",
    "# plt.figure()\n",
    "# plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "# plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "# plt.title(\"Training and validation loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59edf0f",
   "metadata": {},
   "source": [
    "#### Feature extraction together with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "180f5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating and freezing the VGG16 convolutional base\n",
    "\n",
    "# conv_base  = keras.applications.vgg16.VGG16(\n",
    "#     weights=\"imagenet\",\n",
    "#     include_top=False)\n",
    "# conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e0f38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the list of trainable weights before and after freezing\n",
    "\n",
    "# conv_base.trainable = True\n",
    "# print(\"This is the number of trainable weights \"\n",
    "#       \"before freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc616883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base.trainable = False\n",
    "# print(\"This is the number of trainable weights \"\n",
    "#       \"after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7e1d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a data augmentation stage and a classifier to the convolutional base\n",
    "\n",
    "# data_augmentation = keras.Sequential(\n",
    "#     [\n",
    "#         layers.RandomFlip(\"horizontal\"),\n",
    "#         layers.RandomRotation(0.1),\n",
    "#         layers.RandomZoom(0.2),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# inputs = keras.Input(shape=(180, 180, 3))\n",
    "# x = data_augmentation(inputs)\n",
    "# x = keras.applications.vgg16.preprocess_input(x)\n",
    "# x = conv_base(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(256)(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# model = keras.Model(inputs, outputs)\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#               optimizer=\"rmsprop\",\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9eb4895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
    "#         save_best_only=True,\n",
    "#         monitor=\"val_loss\")\n",
    "# ]\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=50,\n",
    "#     validation_data=validation_dataset,\n",
    "#     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e7b077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on the test set\n",
    "\n",
    "# test_model = keras.models.load_model(\n",
    "#     \"feature_extraction_with_data_augmentation.keras\")\n",
    "# test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "# print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0cbf0",
   "metadata": {},
   "source": [
    "#### Fine-tuning a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58dc24ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20bdf236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all layers until the fourth from the last\n",
    "\n",
    "# conv_base.trainable = True\n",
    "# for layer in conv_base.layers[:-4]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbfc11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the model\n",
    "\n",
    "# model.compile(loss=\"binary_crossentropy\",\n",
    "#               optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         filepath=\"fine_tuning.keras\",\n",
    "#         save_best_only=True,\n",
    "#         monitor=\"val_loss\")\n",
    "# ]\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=30,\n",
    "#     validation_data=validation_dataset,\n",
    "#     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75715827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"fine_tuning.keras\")\n",
    "# test_loss, test_acc = model.evaluate(test_dataset)\n",
    "# print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e86090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
